p8105\_mtp\_zdz2101
================
Zelos Zhu
10/22/2018

First, load, tidy, and otherwise wrangle the data. Your final dataset should include all originally observed variables and values; have useful variable names; and code data with reasonable variable classes. Describe the resulting dataset (e.g. what variables exist, how many observations, etc). Discuss any additional exploratory analyses you conduct, but only include results you think are interesting (e.g. visually inspect distributions for outliers, but include only if these are informative).

Traditional analyses of accelerometer data focus on the total activity over the day. Using your tidied dataset, aggregate accross minutes to create a total activity variable. Using these data, explore the hypothesis that this participant became more active over time. You may want to want to make comparisons visually and / or quantitatively, or using formal statistical analyses. Additionally, examine the possibility that day of the week affects activity (in isolation and in addition to the effect of time).

One advantage of accelerometer data is the ability to inspect activity over the course of the day, rather than aggregating over 24 hours. Explore the distribution of activity counts in the full dataset, taking into account other variables of interest. Make a visualization that shows the 24-hour activity “profiles” for each day. Also visualize effects of time and day of the week on 24-hour activity profiles; incorporating smooth estimates of mean activity profiles may clarify these effects. Comment on relationships you think are interesting. (No formal statistical analyses are needed.)

``` r
library(tidyverse)
```

    ## ── Attaching packages ─────────────────────────────────────────────────────────────────────────────────────────────────── tidyverse 1.2.1 ──

    ## ✔ ggplot2 3.0.0     ✔ purrr   0.2.5
    ## ✔ tibble  1.4.2     ✔ dplyr   0.7.6
    ## ✔ tidyr   0.8.1     ✔ stringr 1.3.1
    ## ✔ readr   1.1.1     ✔ forcats 0.3.0

    ## ── Conflicts ────────────────────────────────────────────────────────────────────────────────────────────────────── tidyverse_conflicts() ──
    ## ✖ dplyr::filter() masks stats::filter()
    ## ✖ dplyr::lag()    masks stats::lag()

``` r
library(readr)
library(wordcountaddin)
library(ggridges)
```

    ## 
    ## Attaching package: 'ggridges'

    ## The following object is masked from 'package:ggplot2':
    ## 
    ##     scale_discrete_manual

``` r
library(ggpubr)
```

    ## Loading required package: magrittr

    ## 
    ## Attaching package: 'magrittr'

    ## The following object is masked from 'package:purrr':
    ## 
    ##     set_names

    ## The following object is masked from 'package:tidyr':
    ## 
    ##     extract

``` r
wordcountaddin::text_stats("p8105_mtp_zdz2101.Rmd")
```

| Method          | koRpus      | stringi       |
|:----------------|:------------|:--------------|
| Word count      | 437         | 411           |
| Character count | 2690        | 2689          |
| Sentence count  | 33          | Not available |
| Reading time    | 2.2 minutes | 2.1 minutes   |

``` r
accelero_data <- read_csv("data/p8105_mtp_data.csv") %>%
  gather(., key = "activity", value = "activity_value", 3:1442) %>%
  mutate(day = factor(day, levels = c("Sunday", "Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday")),
         day_id = (7 * week) - (abs(as.numeric(day) - 7)),
         minute = as.numeric(str_replace_all(activity, "activity.",""))) %>%
  mutate(hour = floor((minute-1)/60)) %>% 
  select(day_id, week, day, hour, activity, minute, activity_value) %>%
  arrange(week,day)
```

    ## Parsed with column specification:
    ## cols(
    ##   .default = col_double(),
    ##   week = col_integer(),
    ##   day = col_character()
    ## )

    ## See spec(...) for full column specifications.

``` r
accelero_data
```

    ## # A tibble: 473,760 x 7
    ##    day_id  week day     hour activity    minute activity_value
    ##     <dbl> <int> <fct>  <dbl> <chr>        <dbl>          <dbl>
    ##  1      1     1 Sunday     0 activity.1       1              1
    ##  2      1     1 Sunday     0 activity.2       2              1
    ##  3      1     1 Sunday     0 activity.3       3              1
    ##  4      1     1 Sunday     0 activity.4       4              1
    ##  5      1     1 Sunday     0 activity.5       5              1
    ##  6      1     1 Sunday     0 activity.6       6              1
    ##  7      1     1 Sunday     0 activity.7       7              1
    ##  8      1     1 Sunday     0 activity.8       8              1
    ##  9      1     1 Sunday     0 activity.9       9              1
    ## 10      1     1 Sunday     0 activity.10     10              1
    ## # ... with 473,750 more rows

``` r
#used clever trick for to figure out day_id (a linear transform of week and day)
```

The final dataset I have attained has 473760 observations and 7 variables. The number of observations was as expected as there are 60 minutes in an hour, 24 hours a day, 7 days a week, and 47 weeks worth of accelerometer readings, in which case the product of these 4 numbers gets you 473760. My variables are as follows:

1.  **day\_id**: Identifies the day of the study with the assumption that sunday is the beginning of a week, so week 1 sunday is day 1, week 2 sunday is day 8, etc.
2.  **week**: Identifies what week of the study this patient was wearing the accelerometer
3.  **day**: Identifies what weekday it is, which I recoded to as a factor
4.  **hour**: Identifies what hour of the day it is (24 hour/military time)
5.  **activity**: A column of essentially the column names of the original file, this was my "key" for when using the gather function, I left it as is to "preserve the original observations"
6.  **minute**: Identifies minute of day 1 being 12:00 - 12:01 AM, 1440 being 11:59 PM - 12:00 AM
7.  **activity\_value**: The accelerometer activity reading for a particular moment in time

``` r
day_aggregate <- accelero_data %>%
  group_by(day_id, week, day) %>%
  summarize(total_activity = sum(activity_value),
            mean = mean(activity_value),
            min = quantile(activity_value, 0),
            q1 = quantile(activity_value, 0.25),
            median = quantile(activity_value, 0.50),
            q3 = quantile(activity_value, 0.75),
            max = quantile(activity_value, 1)
            ) %>%
  filter(total_activity != 1440) #get rid of days we don't have any readings

ggplot(day_aggregate, aes(x = day_id, y = total_activity)) + 
  geom_point(aes(color = day), alpha = 0.5) + 
  geom_smooth() 
```

    ## `geom_smooth()` using method = 'loess' and formula 'y ~ x'

![](p8105_mtp_zdz2101_files/figure-markdown_github/Aggregate%20by%20day-1.png)

``` r
ggplot(day_aggregate, aes(x = day_id, y = total_activity, color = day)) + 
  geom_point(alpha = 0.5) + 
  geom_smooth() + 
  facet_grid(~day)
```

    ## `geom_smooth()` using method = 'loess' and formula 'y ~ x'

![](p8105_mtp_zdz2101_files/figure-markdown_github/Aggregate%20by%20day-2.png)

``` r
#Yes there is upward trend overall (by total activity), also seen if you facet by day (saturday is the weirdest)
```

``` r
hour_aggregate <- accelero_data %>%
  group_by(day_id, week, day, hour) %>%
  summarize(hourly_activity_total = sum(activity_value),
            hourly_activity_mean = mean(activity_value)) %>%
  mutate(sleep = ifelse(hour %in% c(0:6,23), "asleep", "awake")) #assuming 8 hours of sleep, 8 lowest median hours, eyeballed it

ggplot(hour_aggregate, aes(x = as.factor(hour), y = hourly_activity_total, color = sleep)) +
  geom_boxplot()
```

![](p8105_mtp_zdz2101_files/figure-markdown_github/Aggregate%20by%20hour/%22activity%20profiles%22-1.png)

``` r
#looks like he gets up around 7/8, goes to bed around 10
```

``` r
top_one_percent <- quantile(accelero_data$activity_value, 0.99)

peaks_df<- accelero_data %>%
  filter(activity_value > top_one_percent) %>%
  select(day_id, hour, minute, activity_value) %>%
  group_by(day_id) %>%
  arrange(day_id, minute)

ggplot(peaks_df, aes(x = minute, y = activity_value, color = as.factor(day_id))) +
  geom_line() + 
  scale_x_continuous(breaks = seq(1,1440,60), labels = 0:23) + 
  xlab("hour of day") +
  geom_hline(yintercept =  2500, color = "black", linetype = "dashed") +
  theme(legend.position="none")
```

![](p8105_mtp_zdz2101_files/figure-markdown_github/Finding%20peak%20times-1.png)

``` r
#still appears to be some noise "below 2500", looks like workout times are above this line

exercise_df <- peaks_df %>%
  filter(activity_value > 2500) %>%
  mutate(study = ifelse(day_id >= 116, "Second Half", "First Half"))

ggplot(exercise_df, aes(x = minute, y = activity_value, color = study)) + 
  geom_jitter(alpha = 0.5) + 
  scale_x_continuous(breaks = seq(1,1440,60), labels = 0:23) + 
  xlab("hour of day") +
  facet_grid(~study)
```

![](p8105_mtp_zdz2101_files/figure-markdown_github/Finding%20peak%20times-2.png)
